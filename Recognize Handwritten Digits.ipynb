{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets.mnist import load_data\n",
    "#data study "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images,train_labels),(test_images,test_labels)=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: (60000, 28, 28)\n",
      "Shape of each Training example : (28, 28)\n",
      "\n",
      "shape of testing data : (10000, 28, 28)\n",
      "shape of each testing example : (28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of training data:\",train_images.shape)\n",
    "print(\"Shape of each Training example :\",train_images[0].shape)\n",
    "print ()\n",
    "print(\"shape of testing data :\",test_images.shape)\n",
    "print(\"shape of each testing example :\",test_images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualization of data\n",
    "#taking  5 images from tha data\n",
    "plt.figure (figsize=(10,10))\n",
    "for i in range(5):\n",
    "  plt.subplot(1,5,i+1)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.imshow(train_images[i],cmap=plt.cm.binary)\n",
    "  plt.xlabel(train_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    " #step 3 =data preprocessing \n",
    " #just bringin in the data in 0-1 range\n",
    " np.unique(train_images[0])\n",
    "train_images=train_images/255.0\n",
    "test_images=test_images/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(128,activation='sigmoid'),\n",
    "    keras.layers.Dense(10,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of weights: (784, 128)\n",
      "Shape of biases: (128,)\n"
     ]
    }
   ],
   "source": [
    "hidden_layer=model.layers[1]\n",
    "weights=hidden_layer.get_weights()\n",
    "print(\"Shape of weights:\",np.shape(weights[0]))\n",
    "print(\"Shape of biases:\",np.shape(weights[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of weights : (128, 10)\n",
      "shape of biases : (10,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_layer=model.layers[2]\n",
    "weights=output_layer.get_weights()\n",
    "print(\"shape of weights :\",np.shape(weights[0]))\n",
    "print(\"shape of biases :\",np.shape(weights[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compilation of model\n",
    "#one input layer on hidden layer and one output layer \n",
    "sgd=keras.optimizers.SGD(lr=0.5,decay=1e-6, momentum=0.5)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "#NN created\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n",
      "54000/54000 [==============================] - 2s 43us/sample - loss: 2.4190 - accuracy: 0.1012 - val_loss: 2.3928 - val_accuracy: 0.0952\n",
      "Epoch 2/10\n",
      "54000/54000 [==============================] - 2s 30us/sample - loss: 2.3511 - accuracy: 0.1030 - val_loss: 2.4077 - val_accuracy: 0.0978\n",
      "Epoch 3/10\n",
      "54000/54000 [==============================] - 1s 25us/sample - loss: 2.3335 - accuracy: 0.1053 - val_loss: 2.3477 - val_accuracy: 0.0978\n",
      "Epoch 4/10\n",
      "54000/54000 [==============================] - 1s 25us/sample - loss: 2.3239 - accuracy: 0.1036 - val_loss: 2.3315 - val_accuracy: 0.0992\n",
      "Epoch 5/10\n",
      "54000/54000 [==============================] - 1s 23us/sample - loss: 2.3186 - accuracy: 0.1042 - val_loss: 2.3212 - val_accuracy: 0.0952\n",
      "Epoch 6/10\n",
      "54000/54000 [==============================] - 1s 23us/sample - loss: 2.3135 - accuracy: 0.1107 - val_loss: 2.3060 - val_accuracy: 0.1045\n",
      "Epoch 7/10\n",
      "54000/54000 [==============================] - 1s 25us/sample - loss: 2.3074 - accuracy: 0.1130 - val_loss: 2.3138 - val_accuracy: 0.0978\n",
      "Epoch 8/10\n",
      "54000/54000 [==============================] - 1s 24us/sample - loss: 2.3035 - accuracy: 0.1157 - val_loss: 2.3110 - val_accuracy: 0.1050\n",
      "Epoch 9/10\n",
      "54000/54000 [==============================] - 1s 26us/sample - loss: 2.2978 - accuracy: 0.1231 - val_loss: 2.2818 - val_accuracy: 0.1113\n",
      "Epoch 10/10\n",
      "54000/54000 [==============================] - 1s 24us/sample - loss: 2.2903 - accuracy: 0.1341 - val_loss: 2.2813 - val_accuracy: 0.1980\n"
     ]
    }
   ],
   "source": [
    "#model Training \n",
    "history=model.fit(train_images,train_labels,epochs=10,batch_size=100,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-2b66fd261ee5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'c' is not defined"
     ]
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 42us/sample - loss: 2.2825 - accuracy: 0.1920\n",
      "Test accuracy 0.192\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_acc=model.evaluate(test_images,test_labels)\n",
    "print('Test accuracy',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confidence(images,labels,predictions):\n",
    "  plt.figure(figsize=(15,30))\n",
    "  plt.subplots_adjust(top=0.99,bottom=0.01,hspace=1.5,wspace=0.4)\n",
    "  plot_index=0\n",
    "  for i in range(len(images)):\n",
    "    plot_index+=1\n",
    "    plt.subplot(len(images),2,plot_index)\n",
    "    plt.imshow(images[i],cmap=plt.cm.binary)\n",
    "    correct_label=str(labels[i])\n",
    "    predicted_label=str(np.argmax(predictions[i]))\n",
    "    title='Corrected Label:'+str(labels[i])+'\\n'+ 'predicted_label:'+str(np.argmax(predictions[i]))\n",
    "    \n",
    "    if predicted_label !=correct_label:\n",
    "      plt.title(title,backgroundcolor='r',color='w')\n",
    "    else:\n",
    "      plt.title(title,backgroundcolor='g',color='w')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plot_index+=1\n",
    "    plt.subplot(len(images),2,plot_index)\n",
    "    plt.bar(range(10),predictions[i])\n",
    "    plt.xticks(range(10))\n",
    "    plt.ylim(0,1)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize predictions from datset\n",
    "images= test_images[:10]\n",
    "labels= test_labels[:10]\n",
    "test_predictions= predictions[:10]\n",
    "plot_confidence(images,labels,test_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visual prediction fo incorrect samples\n",
    "incorrect_indices=list()\n",
    "for i in range (len(predictions)):\n",
    "    predicted_label=np.argmax(predictions[i])\n",
    "    if predicted_label!=test_labels[i]:\n",
    "        incorrect_indices.append(i)\n",
    "print('Number of incorrectly classified images :',len(incorrect_indices))\n",
    "incorrect_indices=incorrect_indices[:10]\n",
    "\n",
    "incorrect_images=[test_images[i] for i in incorrect_indices]\n",
    "incorrect_labels=[test_labels[i] for i in incorrect_indices]\n",
    "incorrect_predictions=[predictions[i] for i in incorrect_indices]\n",
    "\n",
    "plot_confidence(incorrect_images,incorrect_labels,incorrect_predictions)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
